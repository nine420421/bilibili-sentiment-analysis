import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import jieba
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import os
import platform
import base64
import requests
from io import BytesIO
import numpy as np
from PIL import Image
import matplotlib.font_manager as fm
import tempfile

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è°ƒè¯•ä¿¡æ¯å¼€å…³
DEBUG = st.sidebar.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=True)

def debug_info(message):
    """æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯"""
    if DEBUG:
        st.sidebar.write(f"ğŸ” {message}")

def get_simple_font():
    """è·å–ç®€å•å¯ç”¨çš„å­—ä½“"""
    try:
        # ç›´æ¥ä½¿ç”¨matplotlibé»˜è®¤å­—ä½“
        return None
    except Exception as e:
        debug_info(f"å­—ä½“è·å–å¤±è´¥: {e}")
        return None

def create_simple_wordcloud_direct(word_freq, max_words=100, colormap='viridis', background_color='white'):
    """ç›´æ¥åˆ›å»ºè¯äº‘ - ç®€åŒ–ç‰ˆæœ¬"""
    try:
        # ä½¿ç”¨æœ€åŸºæœ¬çš„é…ç½®
        wc = WordCloud(
            width=1200,
            height=600,
            background_color=background_color,
            max_words=max_words,
            colormap=colormap,
            random_state=42,
            relative_scaling=0.3,
            min_font_size=10,
            max_font_size=120,
            collocations=False
        )
        
        # ç”Ÿæˆè¯äº‘
        wordcloud = wc.generate_from_frequencies(word_freq)
        return wordcloud
    except Exception as e:
        debug_info(f"ç®€å•è¯äº‘å¤±è´¥: {e}")
        return None

def create_text_cloud_manual(word_freq, max_words=50, colormap='viridis', background_color='white'):
    """åˆ›å»ºæ–‡æœ¬äº‘ - ç¡®ä¿æ˜¾ç¤ºæ–‡å­—"""
    try:
        # é™åˆ¶è¯æ±‡æ•°é‡
        top_words = word_freq.most_common(max_words)
        if not top_words:
            return None
            
        words = [word for word, count in top_words]
        counts = [count for word, count in top_words]
        
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(16, 9), dpi=100)
        
        # è®¾ç½®èƒŒæ™¯
        fig.patch.set_facecolor(background_color)
        ax.set_facecolor(background_color)
        
        # è®¡ç®—å­—ä½“å¤§å°
        max_count = max(counts)
        min_count = min(counts)
        
        # ç®€å•çš„ç½‘æ ¼å¸ƒå±€
        cols = 6  # æ¯è¡Œ6ä¸ªè¯
        rows = (len(words) + cols - 1) // cols
        
        # é¢œè‰²æ˜ å°„
        cmap = plt.cm.get_cmap(colormap)
        
        for i, (word, count) in enumerate(zip(words, counts)):
            # è®¡ç®—ä½ç½®
            row = i // cols
            col = i % cols
            
            # è®¡ç®—å­—ä½“å¤§å° (20-60ä¹‹é—´)
            if max_count == min_count:
                fontsize = 40
            else:
                fontsize = 20 + 40 * (count - min_count) / (max_count - min_count)
            
            # è®¡ç®—ä½ç½®
            x = (col + 0.5) * (1.0 / cols)
            y = 1.0 - (row + 0.5) * (1.0 / rows)
            
            # è®¡ç®—é¢œè‰²
            color = cmap(i / len(words))
            
            # ç»˜åˆ¶æ–‡å­—
            ax.text(x, y, word, 
                   fontsize=fontsize,
                   ha='center', va='center',
                   color=color,
                   transform=ax.transAxes)
        
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.axis('off')
        ax.set_title('è¯äº‘å›¾ - æ‰‹åŠ¨å¸ƒå±€', fontsize=20, pad=20)
        
        return fig
        
    except Exception as e:
        debug_info(f"æ–‡æœ¬äº‘åˆ›å»ºå¤±è´¥: {e}")
        return None

def create_fallback_chart(word_freq, title="é«˜é¢‘è¯æ±‡"):
    """åˆ›å»ºå¤‡ç”¨å›¾è¡¨"""
    try:
        top_words = word_freq.most_common(20)
        
        if not top_words:
            return None
            
        words = [word for word, _ in top_words]
        counts = [count for _, count in top_words]
        
        # ä½¿ç”¨plotlyåˆ›å»ºæ°´å¹³æ¡å½¢å›¾
        fig = px.bar(
            x=counts,
            y=words,
            orientation='h',
            title=title,
            labels={'x': 'å‡ºç°æ¬¡æ•°', 'y': 'è¯æ±‡'},
            color=counts,
            color_continuous_scale='blues'
        )
        
        fig.update_layout(
            showlegend=False,
            height=600,
            yaxis={'categoryorder': 'total ascending'}
        )
        
        return fig
        
    except Exception as e:
        debug_info(f"å¤‡ç”¨å›¾è¡¨åˆ›å»ºå¤±è´¥: {e}")
        return None

def get_words_from_segmented(segmented_str):
    """ä»åˆ†è¯å­—ç¬¦ä¸²ä¸­æå–è¯æ±‡"""
    if pd.isna(segmented_str) or not isinstance(segmented_str, str):
        return []
    
    try:
        clean_str = segmented_str.strip()
        
        # å¤„ç†åˆ—è¡¨æ ¼å¼
        if clean_str.startswith('[') and clean_str.endswith(']'):
            content = clean_str[1:-1].replace("'", "").replace('"', '')
            words = [word.strip() for word in content.split(',')]
        else:
            words = clean_str.split()
        
        # è¿‡æ»¤
        filtered_words = []
        for word in words:
            word_clean = word.strip()
            if (len(word_clean) > 0 and 
                not word_clean.isspace() and
                word_clean not in [' ', '', '\\n', '\\t']):
                filtered_words.append(word_clean)
        
        return filtered_words
        
    except Exception as e:
        debug_info(f"åˆ†è¯è§£æé”™è¯¯: {e}")
        return []

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="Bç«™è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide"
)

def main():
    # æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ¯ Bç«™è§†é¢‘è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ å’Œè®¾ç½®
    st.sidebar.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ è¯„è®ºæ•°æ®CSVæ–‡ä»¶", type=['csv'])

    if uploaded_file is not None:
        # è¯»å–æ•°æ®
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼Œå…± {len(df)} è¡Œ")
        except Exception as e:
            st.error(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
            return
        
        # æ•°æ®é¢„å¤„ç†
        if 'post_time' in df.columns:
            df['post_time'] = pd.to_datetime(df['post_time'], errors='coerce')

        # æ•°æ®æ£€æŸ¥
        st.sidebar.subheader("ğŸ“‹ æ•°æ®æ£€æŸ¥")
        st.sidebar.write(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        
        # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['segmented_words', 'sentiment_label']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            st.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            st.info("è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å« 'segmented_words' å’Œ 'sentiment_label' åˆ—")
            return

        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        st.header("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æ€»è¯„è®ºæ•°", len(df))
        with col2:
            positive_count = len(df[df['sentiment_label'] == 'ç§¯æ'])
            st.metric("ç§¯æè¯„è®º", positive_count)
        with col3:
            negative_count = len(df[df['sentiment_label'] == 'æ¶ˆæ'])
            st.metric("æ¶ˆæè¯„è®º", negative_count)
        with col4:
            neutral_count = len(df[df['sentiment_label'] == 'ä¸­æ€§'])
            st.metric("ä¸­æ€§è¯„è®º", neutral_count)

        # æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
        st.header("ğŸ­ æƒ…æ„Ÿåˆ†å¸ƒåˆ†æ")
        col1, col2 = st.columns(2)

        with col1:
            sentiment_counts = df['sentiment_label'].value_counts()
            fig_pie = px.pie(
                values=sentiment_counts.values,
                names=sentiment_counts.index,
                title='è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ',
                color=sentiment_counts.index,
                color_discrete_map={'ç§¯æ': '#2E8B57', 'æ¶ˆæ': '#DC143C', 'ä¸­æ€§': '#1E90FF'}
            )
            st.plotly_chart(fig_pie, use_container_width=True)

        with col2:
            if 'sentiment_score' in df.columns:
                fig_hist = px.histogram(
                    df, x='sentiment_score',
                    title='æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ',
                    nbins=20,
                    color_discrete_sequence=['#636EFA']
                )
                fig_hist.add_vline(x=0.5, line_dash="dash", line_color="red")
                st.plotly_chart(fig_hist, use_container_width=True)

        # æ—¶é—´è¶‹åŠ¿åˆ†æ
        st.header("ğŸ“ˆ è¯„è®ºæ—¶é—´è¶‹åŠ¿")
        if 'post_time' in df.columns:
            daily_stats = df.groupby(df['post_time'].dt.date).agg({
                'sentiment_score': 'mean',
                'comment_id': 'count'
            }).reset_index()

            col1, col2 = st.columns(2)

            with col1:
                fig_trend = px.line(
                    daily_stats, x='post_time', y='sentiment_score',
                    title='æ¯æ—¥å¹³å‡æƒ…æ„Ÿå¾—åˆ†è¶‹åŠ¿',
                    labels={'sentiment_score': 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†', 'post_time': 'æ—¥æœŸ'}
                )
                st.plotly_chart(fig_trend, use_container_width=True)

            with col2:
                fig_count = px.bar(
                    daily_stats, x='post_time', y='comment_id',
                    title='æ¯æ—¥è¯„è®ºæ•°é‡',
                    labels={'comment_id': 'è¯„è®ºæ•°é‡', 'post_time': 'æ—¥æœŸ'}
                )
                st.plotly_chart(fig_count, use_container_width=True)
        else:
            st.info("æ•°æ®ä¸­æ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œæ— æ³•æ˜¾ç¤ºæ—¶é—´è¶‹åŠ¿")

        # è¯äº‘åˆ†æ
        st.header("â˜ï¸ è¯äº‘åˆ†æ")

        # æƒ…æ„Ÿé€‰æ‹©
        sentiment_option = st.selectbox(
            "é€‰æ‹©æƒ…æ„Ÿç±»å‹æŸ¥çœ‹è¯äº‘:",
            ["å…¨éƒ¨è¯„è®º", "ç§¯æè¯„è®º", "æ¶ˆæè¯„è®º", "ä¸­æ€§è¯„è®º"],
            key="sentiment_selector"
        )

        # è¯äº‘è®¾ç½®é€‰é¡¹
        col1, col2, col3 = st.columns(3)
        with col1:
            max_words = st.slider("æœ€å¤§è¯æ±‡æ•°é‡", 20, 100, 50, key="max_words_slider")
        with col2:
            background_color = st.selectbox("èƒŒæ™¯é¢œè‰²", 
                ["white", "black", "#f0f0f0"], key="bg_color_selector")
        with col3:
            colormap_option = st.selectbox("é¢œè‰²æ–¹æ¡ˆ", 
                ["viridis", "plasma", "spring", "summer", "autumn", "winter"], 
                key="colormap_selector")

        # ç”Ÿæˆè¯äº‘
        if st.button("ç”Ÿæˆè¯äº‘", type="primary", key="generate_wordcloud"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯äº‘..."):
                # æ ¹æ®é€‰æ‹©è¿‡æ»¤æ•°æ®
                if sentiment_option == "å…¨éƒ¨è¯„è®º":
                    target_df = df
                elif sentiment_option == "ç§¯æè¯„è®º":
                    target_df = df[df['sentiment_label'] == 'ç§¯æ']
                elif sentiment_option == "æ¶ˆæè¯„è®º":
                    target_df = df[df['sentiment_label'] == 'æ¶ˆæ']
                else:
                    target_df = df[df['sentiment_label'] == 'ä¸­æ€§']

                debug_info(f"ç›®æ ‡æ•°æ®è¡Œæ•°: {len(target_df)}")
                
                if len(target_df) == 0:
                    st.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ° {sentiment_option} çš„æ•°æ®")
                    return

                # å‡†å¤‡æ–‡æœ¬æ•°æ®
                all_words = []
                for seg_text in target_df['segmented_words']:
                    words = get_words_from_segmented(seg_text)
                    all_words.extend(words)

                if all_words:
                    # ç»Ÿè®¡è¯é¢‘
                    word_freq = Counter(all_words)
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.success(f"âœ… æˆåŠŸæå– {len(all_words)} ä¸ªè¯æ±‡ï¼Œ{len(word_freq)} ä¸ªä¸åŒè¯æ±‡")
                    
                    # æ˜¾ç¤ºå‰10ä¸ªé«˜é¢‘è¯
                    top_10 = word_freq.most_common(10)
                    top_words_str = "ã€".join([f"{word}({count})" for word, count in top_10])
                    st.info(f"ğŸ“Š å‰10ä¸ªé«˜é¢‘è¯: {top_words_str}")

                    # æ–¹æ¡ˆ1: å°è¯•ç®€å•è¯äº‘
                    st.subheader("æ–¹æ¡ˆ1: ç®€å•è¯äº‘")
                    wordcloud = create_simple_wordcloud_direct(
                        word_freq,
                        max_words=max_words,
                        colormap=colormap_option,
                        background_color=background_color
                    )

                    if wordcloud is not None:
                        # æ˜¾ç¤ºè¯äº‘
                        fig, ax = plt.subplots(figsize=(16, 8))
                        ax.imshow(wordcloud, interpolation='bilinear')
                        ax.axis('off')
                        ax.set_title(f'{sentiment_option} - è¯äº‘å›¾', fontsize=20, pad=20)
                        fig.patch.set_facecolor(background_color)
                        st.pyplot(fig)
                        plt.close(fig)
                        st.success("ğŸ‰ ç®€å•è¯äº‘ç”ŸæˆæˆåŠŸï¼")
                    else:
                        st.warning("âŒ ç®€å•è¯äº‘ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•æ–¹æ¡ˆ2")

                        # æ–¹æ¡ˆ2: æ‰‹åŠ¨æ–‡æœ¬äº‘
                        st.subheader("æ–¹æ¡ˆ2: æ–‡æœ¬äº‘å¸ƒå±€")
                        text_fig = create_text_cloud_manual(
                            word_freq,
                            max_words=min(max_words, 30),  # æ‰‹åŠ¨å¸ƒå±€é™åˆ¶è¯æ±‡æ•°
                            colormap=colormap_option,
                            background_color=background_color
                        )

                        if text_fig is not None:
                            st.pyplot(text_fig)
                            plt.close(text_fig)
                            st.success("ğŸ‰ æ–‡æœ¬äº‘ç”ŸæˆæˆåŠŸï¼")
                        else:
                            st.error("âŒ æ–‡æœ¬äº‘ç”Ÿæˆå¤±è´¥")

                            # æ–¹æ¡ˆ3: ä½¿ç”¨plotlyå¤‡ç”¨å›¾è¡¨
                            st.subheader("æ–¹æ¡ˆ3: é«˜é¢‘è¯æ±‡å›¾è¡¨")
                            fallback_fig = create_fallback_chart(
                                word_freq, 
                                f'{sentiment_option} - é«˜é¢‘è¯æ±‡'
                            )
                            
                            if fallback_fig is not None:
                                st.plotly_chart(fallback_fig, use_container_width=True)
                                st.info("ğŸ“Š ä½¿ç”¨é«˜é¢‘è¯æ±‡å›¾è¡¨ä½œä¸ºè¯äº‘æ›¿ä»£")
                            else:
                                st.error("âŒ æ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥äº†")

                    # æ˜¾ç¤ºé«˜é¢‘è¯è¡¨æ ¼
                    st.subheader("ğŸ“‹ é«˜é¢‘è¯æ±‡TOP20")
                    top_words = word_freq.most_common(20)
                    word_df = pd.DataFrame(top_words, columns=['è¯æ±‡', 'å‡ºç°æ¬¡æ•°'])
                    st.dataframe(word_df, use_container_width=True, height=400)

                else:
                    st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„è¯æ±‡æ•°æ®æ¥ç”Ÿæˆè¯äº‘")

        # è¯„è®ºè¯¦æƒ…æŸ¥çœ‹
        st.header("ğŸ’¬ è¯„è®ºè¯¦æƒ…æµè§ˆ")

        # æƒ…æ„Ÿç­›é€‰
        sentiment_filter = st.multiselect(
            "ç­›é€‰æƒ…æ„Ÿç±»å‹:",
            options=['ç§¯æ', 'æ¶ˆæ', 'ä¸­æ€§'],
            default=['ç§¯æ', 'æ¶ˆæ', 'ä¸­æ€§'],
            key="sentiment_filter"
        )

        # ç‚¹èµæ•°èŒƒå›´ç­›é€‰
        min_likes = 0
        max_likes = 100
        if 'like_count' in df.columns:
            min_likes = int(df['like_count'].min())
            max_likes = int(df['like_count'].max())
            
            min_likes, max_likes = st.slider(
                "ç‚¹èµæ•°èŒƒå›´:",
                min_value=min_likes,
                max_value=max_likes,
                value=(0, max_likes),
                key="like_slider"
            )

        # åº”ç”¨ç­›é€‰
        filtered_df = df[df['sentiment_label'].isin(sentiment_filter)]
        
        if 'like_count' in df.columns:
            filtered_df = filtered_df[
                (filtered_df['like_count'] >= min_likes) & 
                (filtered_df['like_count'] <= max_likes)
            ]

        # æ˜¾ç¤ºç­›é€‰åçš„è¯„è®º
        st.subheader(f"ç­›é€‰ç»“æœ: {len(filtered_df)} æ¡è¯„è®º")

        # æ’åºé€‰é¡¹
        sort_options = ["é»˜è®¤æ’åº"]
        if 'like_count' in df.columns:
            sort_options.append("æŒ‰ç‚¹èµæ•°é™åº")
        if 'sentiment_score' in df.columns:
            sort_options.append("æŒ‰æƒ…æ„Ÿå¾—åˆ†é™åº")
        if 'post_time' in df.columns:
            sort_options.append("æŒ‰æ—¶é—´é™åº")
            
        sort_option = st.selectbox("æ’åºæ–¹å¼:", sort_options, key="sort_selector")

        if sort_option == "æŒ‰ç‚¹èµæ•°é™åº" and 'like_count' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('like_count', ascending=False)
        elif sort_option == "æŒ‰æƒ…æ„Ÿå¾—åˆ†é™åº" and 'sentiment_score' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('sentiment_score', ascending=False)
        elif sort_option == "æŒ‰æ—¶é—´é™åº" and 'post_time' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('post_time', ascending=False)

        # åˆ†é¡µæ˜¾ç¤º
        page_size = 10
        total_pages = max(1, (len(filtered_df) // page_size) + 1)

        page_number = st.number_input("é¡µç ", min_value=1, max_value=total_pages, value=1, key="page_selector")
        start_idx = (page_number - 1) * page_size
        end_idx = start_idx + page_size

        # æ˜¾ç¤ºè¯„è®º
        for idx, row in filtered_df.iloc[start_idx:end_idx].iterrows():
            # æ ¹æ®æƒ…æ„Ÿè®¾ç½®é¢œè‰²
            if row['sentiment_label'] == 'ç§¯æ':
                color = "ğŸŸ¢"
                border_color = "#2E8B57"
            elif row['sentiment_label'] == 'æ¶ˆæ':
                color = "ğŸ”´"
                border_color = "#DC143C"
            else:
                color = "ğŸ”µ"
                border_color = "#1E90FF"

            # æ˜¾ç¤ºè¯„è®ºå¡ç‰‡
            st.markdown(f"""
            <div style="border-left: 4px solid {border_color}; padding: 10px; margin: 10px 0; background-color: #f8f9fa;">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <strong>{color} {row['user_name'] if 'user_name' in row else 'åŒ¿åç”¨æˆ·'}</strong>
                    <span>ğŸ‘ {row['like_count'] if 'like_count' in row else 0} | æƒ…æ„Ÿ: {row['sentiment_score'] if 'sentiment_score' in row else 'N/A'}</span>
                </div>
                <p style="margin: 5px 0;">{row['content_cleaned'] if 'content_cleaned' in row else 'æ— å†…å®¹'}</p>
                <small>æ—¶é—´: {row['post_time'] if 'post_time' in row else 'æœªçŸ¥'}</small>
            </div>
            """, unsafe_allow_html=True)

    else:
        # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶æ—¶çš„å±•ç¤º
        st.info("ğŸ‘† è¯·åœ¨å·¦ä¾§ä¸Šä¼ Bç«™è¯„è®ºæ•°æ®CSVæ–‡ä»¶å¼€å§‹åˆ†æ")

        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. **å‡†å¤‡æ•°æ®**: ç¡®ä¿CSVæ–‡ä»¶åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
           - `segmented_words`: åˆ†è¯ç»“æœ
           - `sentiment_label`: æƒ…æ„Ÿæ ‡ç­¾
           - å…¶ä»–å¯é€‰å­—æ®µ

        2. **ä¸Šä¼ æ–‡ä»¶**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ CSVæ–‡ä»¶

        3. **ç”Ÿæˆè¯äº‘**: ç³»ç»Ÿä¼šå°è¯•å¤šç§æ–¹æ¡ˆç¡®ä¿è¯äº‘æ˜¾ç¤º

        4. **æ¢ç´¢åˆ†æ**: æŸ¥çœ‹å„ç§å¯è§†åŒ–å›¾è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
        """)

if __name__ == "__main__":
    main()
