import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import jieba
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import os
import platform
import base64
import requests
from io import BytesIO
import numpy as np
from PIL import Image

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è°ƒè¯•ä¿¡æ¯å¼€å…³
DEBUG = st.sidebar.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=True)

def debug_info(message):
    """æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯"""
    if DEBUG:
        st.sidebar.write(f"ğŸ” {message}")

def download_chinese_font():
    """ä¸‹è½½ä¸­æ–‡å­—ä½“ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ"""
    try:
        # å°è¯•ä¸‹è½½æ€æºé»‘ä½“
        font_url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Regular.otf"
        response = requests.get(font_url, timeout=10)
        if response.status_code == 200:
            font_path = "./NotoSansCJKsc-Regular.otf"
            with open(font_path, "wb") as f:
                f.write(response.content)
            debug_info(f"ä¸‹è½½å­—ä½“åˆ°: {font_path}")
            return font_path
    except Exception as e:
        debug_info(f"å­—ä½“ä¸‹è½½å¤±è´¥: {e}")
    return None

def get_chinese_font():
    """è·å–ä¸­æ–‡å­—ä½“ - å¤šç§æ–¹æ¡ˆ"""
    font_paths = []
    
    # æ–¹æ¡ˆ1: ä¸‹è½½çš„å­—ä½“
    downloaded_font = download_chinese_font()
    if downloaded_font and os.path.exists(downloaded_font):
        return downloaded_font
    
    # æ–¹æ¡ˆ2: ç³»ç»Ÿå­—ä½“
    system = platform.system()
    
    if system == "Windows":
        font_paths = [
            "C:/Windows/Fonts/simhei.ttf",
            "C:/Windows/Fonts/msyh.ttc", 
            "C:/Windows/Fonts/simsun.ttc",
            "C:/Windows/Fonts/arial.ttf"
        ]
    elif system == "Darwin":  # macOS
        font_paths = [
            "/System/Library/Fonts/PingFang.ttc",
            "/System/Library/Fonts/Helvetica.ttc",
            "/Library/Fonts/Arial Unicode.ttf",
            "/System/Library/Fonts/Arial.ttf"
        ]
    else:  # Linux
        font_paths = [
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
            "/usr/share/fonts/truetype/arphic/uming.ttc"
        ]
    
    for font_path in font_paths:
        if os.path.exists(font_path):
            debug_info(f"æ‰¾åˆ°ç³»ç»Ÿå­—ä½“: {font_path}")
            return font_path
    
    # æ–¹æ¡ˆ3: ä½¿ç”¨matplotlibçš„å­—ä½“
    try:
        from matplotlib import font_manager
        fonts = [f.name for f in font_manager.fontManager.ttflist if 'CJK' in f.name or 'Chinese' in f.name or 'SC' in f.name]
        if fonts:
            debug_info(f"æ‰¾åˆ°matplotlibå­—ä½“: {fonts[0]}")
            # è·å–å­—ä½“è·¯å¾„
            for f in font_manager.fontManager.ttflist:
                if f.name == fonts[0]:
                    return f.fname
    except Exception as e:
        debug_info(f"matplotlibå­—ä½“æœç´¢å¤±è´¥: {e}")
    
    debug_info("æœªæ‰¾åˆ°ä»»ä½•ä¸­æ–‡å­—ä½“")
    return None

def create_wordcloud_with_fallback(word_freq, font_path, width=800, height=400, max_words=100, colormap='viridis'):
    """åˆ›å»ºè¯äº‘ï¼Œå¸¦æœ‰å¤šç§å›é€€æ–¹æ¡ˆ"""
    
    # åŸºç¡€é…ç½®
    wc_config = {
        'width': width,
        'height': height,
        'background_color': 'white',
        'max_words': max_words,
        'colormap': colormap,
        'relative_scaling': 0.3,  # é™ä½ç›¸å¯¹ç¼©æ”¾ï¼Œè®©å¤§å°å·®å¼‚æ›´æ˜æ˜¾
        'random_state': 42,
        'prefer_horizontal': 0.8,  # åå¥½æ°´å¹³æ–¹å‘
        'scale': 2,  # æé«˜åˆ†è¾¨ç‡
        'min_font_size': 10,
        'max_font_size': 100,
    }
    
    # æ–¹æ¡ˆ1: ä½¿ç”¨æŒ‡å®šå­—ä½“
    if font_path and os.path.exists(font_path):
        wc_config['font_path'] = font_path
        debug_info(f"ä½¿ç”¨å­—ä½“: {font_path}")
        try:
            wordcloud = WordCloud(**wc_config).generate_from_frequencies(word_freq)
            debug_info("æ–¹æ¡ˆ1æˆåŠŸ: ä½¿ç”¨æŒ‡å®šå­—ä½“")
            return wordcloud
        except Exception as e:
            debug_info(f"æ–¹æ¡ˆ1å¤±è´¥: {e}")
    
    # æ–¹æ¡ˆ2: ä¸ä½¿ç”¨å­—ä½“è·¯å¾„ï¼Œè®©ç³»ç»Ÿé€‰æ‹©
    try:
        if 'font_path' in wc_config:
            del wc_config['font_path']
        wordcloud = WordCloud(**wc_config).generate_from_frequencies(word_freq)
        debug_info("æ–¹æ¡ˆ2æˆåŠŸ: ç³»ç»Ÿé»˜è®¤å­—ä½“")
        return wordcloud
    except Exception as e:
        debug_info(f"æ–¹æ¡ˆ2å¤±è´¥: {e}")
    
    # æ–¹æ¡ˆ3: ä½¿ç”¨è‹±æ–‡æ¨¡å¼ï¼Œåªæ˜¾ç¤ºASCIIå­—ç¬¦
    try:
        # è¿‡æ»¤åªåŒ…å«ASCIIå­—ç¬¦çš„è¯æ±‡
        ascii_freq = {k: v for k, v in word_freq.items() if k.isascii()}
        if ascii_freq:
            wordcloud = WordCloud(**wc_config).generate_from_frequencies(ascii_freq)
            debug_info("æ–¹æ¡ˆ3æˆåŠŸ: ASCIIå­—ç¬¦æ¨¡å¼")
            return wordcloud
        else:
            debug_info("æ–¹æ¡ˆ3å¤±è´¥: æ²¡æœ‰ASCIIå­—ç¬¦")
    except Exception as e:
        debug_info(f"æ–¹æ¡ˆ3å¤±è´¥: {e}")
    
    # æ–¹æ¡ˆ4: æœ€å°é…ç½®
    try:
        minimal_config = {
            'width': width,
            'height': height,
            'background_color': 'white',
            'max_words': min(max_words, 50),
        }
        wordcloud = WordCloud(**minimal_config).generate_from_frequencies(word_freq)
        debug_info("æ–¹æ¡ˆ4æˆåŠŸ: æœ€å°é…ç½®")
        return wordcloud
    except Exception as e:
        debug_info(f"æ–¹æ¡ˆ4å¤±è´¥: {e}")
    
    return None

def display_word_frequency(word_freq, title="é«˜é¢‘è¯æ±‡"):
    """æ˜¾ç¤ºè¯é¢‘çš„å¤‡ç”¨æ–¹æ¡ˆ"""
    top_words = word_freq.most_common(20)
    
    if top_words:
        words = [word for word, _ in top_words]
        counts = [count for _, count in top_words]
        
        fig, ax = plt.subplots(figsize=(12, 8))
        bars = ax.barh(range(len(words)), counts)
        ax.set_yticks(range(len(words)))
        ax.set_yticklabels(words, fontsize=12)
        ax.set_xlabel('å‡ºç°æ¬¡æ•°', fontsize=14)
        ax.set_title(title, fontsize=16, pad=20)
        
        # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
        for i, (bar, count) in enumerate(zip(bars, counts)):
            ax.text(count + 0.1, bar.get_y() + bar.get_height()/2, 
                   str(count), ha='left', va='center', fontsize=10)
        
        plt.tight_layout()
        st.pyplot(fig)

def get_words_from_segmented(segmented_str):
    """ä»åˆ†è¯å­—ç¬¦ä¸²ä¸­æå–è¯æ±‡"""
    if pd.isna(segmented_str) or not isinstance(segmented_str, str):
        return []
    
    try:
        # æ¸…ç†å­—ç¬¦ä¸²
        clean_str = segmented_str.strip()
        
        # å¤šç§æ ¼å¼å¤„ç†
        if clean_str.startswith('[') and clean_str.endswith(']'):
            # æ ¼å¼1: ['word1', 'word2', 'word3']
            words = clean_str.strip("[]").replace("'", "").replace('"', '').split(", ")
        elif '"' in clean_str:
            # æ ¼å¼2: "word1" "word2" "word3"
            words = [word.strip('"') for word in clean_str.split()]
        elif "'" in clean_str:
            # æ ¼å¼3: 'word1' 'word2' 'word3'
            words = [word.strip("'") for word in clean_str.split()]
        else:
            # æ ¼å¼4: word1 word2 word3
            words = clean_str.split()
        
        # è¿‡æ»¤çŸ­è¯ã€ç©ºè¯å’Œçº¯æ•°å­—
        filtered_words = []
        for word in words:
            word_clean = word.strip()
            if (len(word_clean) > 1 and 
                not word_clean.isdigit() and 
                not word_clean.isspace()):
                filtered_words.append(word_clean)
        
        debug_info(f"ä»å­—ç¬¦ä¸²è§£æå‡º {len(filtered_words)} ä¸ªè¯æ±‡")
        return filtered_words
    except Exception as e:
        debug_info(f"åˆ†è¯è§£æé”™è¯¯: {e}")
        return []

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="Bç«™è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide"
)

def main():
    # æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ¯ Bç«™è§†é¢‘è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ å’Œè®¾ç½®
    st.sidebar.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ è¯„è®ºæ•°æ®CSVæ–‡ä»¶", type=['csv'])

    if uploaded_file is not None:
        # è¯»å–æ•°æ®
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼Œå…± {len(df)} è¡Œ")
        except Exception as e:
            st.error(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
            return
        
        # æ•°æ®é¢„å¤„ç†
        if 'post_time' in df.columns:
            df['post_time'] = pd.to_datetime(df['post_time'], errors='coerce')

        # æ•°æ®æ£€æŸ¥
        st.sidebar.subheader("ğŸ“‹ æ•°æ®æ£€æŸ¥")
        st.sidebar.write(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        
        # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['segmented_words', 'sentiment_label']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            st.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            st.info("è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å« 'segmented_words' å’Œ 'sentiment_label' åˆ—")
            return

        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        st.header("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æ€»è¯„è®ºæ•°", len(df))
        with col2:
            positive_count = len(df[df['sentiment_label'] == 'ç§¯æ'])
            st.metric("ç§¯æè¯„è®º", positive_count)
        with col3:
            negative_count = len(df[df['sentiment_label'] == 'æ¶ˆæ'])
            st.metric("æ¶ˆæè¯„è®º", negative_count)
        with col4:
            neutral_count = len(df[df['sentiment_label'] == 'ä¸­æ€§'])
            st.metric("ä¸­æ€§è¯„è®º", neutral_count)

        # è¯äº‘åˆ†æ - æ”¾åœ¨å‰é¢ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
        st.header("â˜ï¸ è¯äº‘åˆ†æ")

        # æƒ…æ„Ÿé€‰æ‹©
        sentiment_option = st.selectbox(
            "é€‰æ‹©æƒ…æ„Ÿç±»å‹æŸ¥çœ‹è¯äº‘:",
            ["å…¨éƒ¨è¯„è®º", "ç§¯æè¯„è®º", "æ¶ˆæè¯„è®º", "ä¸­æ€§è¯„è®º"]
        )

        # è¯äº‘è®¾ç½®é€‰é¡¹
        col1, col2 = st.columns(2)
        with col1:
            max_words = st.slider("æœ€å¤§è¯æ±‡æ•°é‡", 50, 200, 100)
            background_color = st.selectbox("èƒŒæ™¯é¢œè‰²", ["white", "black", "gray"])
        with col2:
            colormap_option = st.selectbox("é¢œè‰²æ–¹æ¡ˆ", 
                ["viridis", "plasma", "inferno", "spring", "summer", "autumn", "winter"])

        # ç”Ÿæˆè¯äº‘
        if st.button("ç”Ÿæˆè¯äº‘", type="primary"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯äº‘..."):
                # æ ¹æ®é€‰æ‹©è¿‡æ»¤æ•°æ®
                if sentiment_option == "å…¨éƒ¨è¯„è®º":
                    target_df = df
                elif sentiment_option == "ç§¯æè¯„è®º":
                    target_df = df[df['sentiment_label'] == 'ç§¯æ']
                elif sentiment_option == "æ¶ˆæè¯„è®º":
                    target_df = df[df['sentiment_label'] == 'æ¶ˆæ']
                else:
                    target_df = df[df['sentiment_label'] == 'ä¸­æ€§']

                debug_info(f"ç›®æ ‡æ•°æ®è¡Œæ•°: {len(target_df)}")
                
                if len(target_df) == 0:
                    st.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ° {sentiment_option} çš„æ•°æ®")
                    return

                # å‡†å¤‡æ–‡æœ¬æ•°æ®
                all_words = []
                for seg_text in target_df['segmented_words']:
                    words = get_words_from_segmented(seg_text)
                    all_words.extend(words)

                if all_words:
                    # ç»Ÿè®¡è¯é¢‘
                    word_freq = Counter(all_words)
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.success(f"âœ… æˆåŠŸæå– {len(all_words)} ä¸ªè¯æ±‡ï¼Œ{len(word_freq)} ä¸ªä¸åŒè¯æ±‡")
                    st.info(f"ğŸ“Š å‰10ä¸ªé«˜é¢‘è¯: {word_freq.most_common(10)}")
                    
                    # è·å–å­—ä½“
                    font_path = get_chinese_font()
                    
                    if font_path:
                        st.success(f"ğŸ¨ ä½¿ç”¨å­—ä½“: {os.path.basename(font_path)}")
                    else:
                        st.warning("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“")

                    # åˆ›å»ºè¯äº‘
                    wordcloud = create_wordcloud_with_fallback(
                        word_freq, 
                        font_path, 
                        max_words=max_words,
                        colormap=colormap_option
                    )

                    if wordcloud is not None:
                        # æ˜¾ç¤ºè¯äº‘
                        fig, ax = plt.subplots(figsize=(15, 8))
                        ax.imshow(wordcloud, interpolation='bilinear')
                        ax.axis('off')
                        ax.set_title(f'{sentiment_option} - è¯äº‘å›¾', 
                                   fontsize=20, pad=20)
                        
                        st.pyplot(fig)
                        st.success("ğŸ‰ è¯äº‘ç”ŸæˆæˆåŠŸï¼")
                        
                    else:
                        st.error("âŒ æ‰€æœ‰è¯äº‘ç”Ÿæˆæ–¹æ¡ˆéƒ½å¤±è´¥äº†")
                        st.info("ğŸ”„ æ˜¾ç¤ºè¯é¢‘æ¡å½¢å›¾ä½œä¸ºæ›¿ä»£")
                        display_word_frequency(word_freq, f'{sentiment_option} - é«˜é¢‘è¯æ±‡')

                    # æ˜¾ç¤ºé«˜é¢‘è¯è¡¨æ ¼
                    st.subheader("ğŸ“‹ é«˜é¢‘è¯æ±‡TOP20")
                    top_words = word_freq.most_common(20)
                    
                    # åˆ›å»ºæ•°æ®æ¡†æ˜¾ç¤º
                    word_df = pd.DataFrame(top_words, columns=['è¯æ±‡', 'å‡ºç°æ¬¡æ•°'])
                    st.dataframe(word_df, use_container_width=True, height=400)

                else:
                    st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„è¯æ±‡æ•°æ®æ¥ç”Ÿæˆè¯äº‘")
                    st.info("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ•°æ®ä¸­çš„ 'segmented_words' åˆ—æ ¼å¼æ˜¯å¦æ­£ç¡®")

        # æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
        st.header("ğŸ­ æƒ…æ„Ÿåˆ†å¸ƒåˆ†æ")
        col1, col2 = st.columns(2)

        with col1:
            sentiment_counts = df['sentiment_label'].value_counts()
            fig_pie = px.pie(
                values=sentiment_counts.values,
                names=sentiment_counts.index,
                title='è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ',
                color=sentiment_counts.index,
                color_discrete_map={'ç§¯æ': '#2E8B57', 'æ¶ˆæ': '#DC143C', 'ä¸­æ€§': '#1E90FF'}
            )
            st.plotly_chart(fig_pie, use_container_width=True)

        with col2:
            if 'sentiment_score' in df.columns:
                fig_hist = px.histogram(
                    df, x='sentiment_score',
                    title='æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ',
                    nbins=20,
                    color_discrete_sequence=['#636EFA']
                )
                fig_hist.add_vline(x=0.5, line_dash="dash", line_color="red")
                st.plotly_chart(fig_hist, use_container_width=True)

        # æ—¶é—´è¶‹åŠ¿åˆ†æ
        st.header("ğŸ“ˆ è¯„è®ºæ—¶é—´è¶‹åŠ¿")
        if 'post_time' in df.columns:
            daily_stats = df.groupby(df['post_time'].dt.date).agg({
                'sentiment_score': 'mean',
                'comment_id': 'count'
            }).reset_index()

            col1, col2 = st.columns(2)

            with col1:
                fig_trend = px.line(
                    daily_stats, x='post_time', y='sentiment_score',
                    title='æ¯æ—¥å¹³å‡æƒ…æ„Ÿå¾—åˆ†è¶‹åŠ¿',
                    labels={'sentiment_score': 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†', 'post_time': 'æ—¥æœŸ'}
                )
                st.plotly_chart(fig_trend, use_container_width=True)

            with col2:
                fig_count = px.bar(
                    daily_stats, x='post_time', y='comment_id',
                    title='æ¯æ—¥è¯„è®ºæ•°é‡',
                    labels={'comment_id': 'è¯„è®ºæ•°é‡', 'post_time': 'æ—¥æœŸ'}
                )
                st.plotly_chart(fig_count, use_container_width=True)

        # è¯„è®ºè¯¦æƒ…æŸ¥çœ‹
        st.header("ğŸ’¬ è¯„è®ºè¯¦æƒ…æµè§ˆ")

        # æƒ…æ„Ÿç­›é€‰
        sentiment_filter = st.multiselect(
            "ç­›é€‰æƒ…æ„Ÿç±»å‹:",
            options=['ç§¯æ', 'æ¶ˆæ', 'ä¸­æ€§'],
            default=['ç§¯æ', 'æ¶ˆæ', 'ä¸­æ€§']
        )

        # ç‚¹èµæ•°èŒƒå›´ç­›é€‰
        min_likes = 0
        max_likes = 100
        if 'like_count' in df.columns:
            min_likes = int(df['like_count'].min())
            max_likes = int(df['like_count'].max())
            
            min_likes, max_likes = st.slider(
                "ç‚¹èµæ•°èŒƒå›´:",
                min_value=min_likes,
                max_value=max_likes,
                value=(0, max_likes)
            )

        # åº”ç”¨ç­›é€‰
        filtered_df = df[df['sentiment_label'].isin(sentiment_filter)]
        
        if 'like_count' in df.columns:
            filtered_df = filtered_df[
                (filtered_df['like_count'] >= min_likes) & 
                (filtered_df['like_count'] <= max_likes)
            ]

        # æ˜¾ç¤ºç­›é€‰åçš„è¯„è®º
        st.subheader(f"ç­›é€‰ç»“æœ: {len(filtered_df)} æ¡è¯„è®º")

        # æ’åºé€‰é¡¹
        sort_options = ["æŒ‰ç‚¹èµæ•°é™åº"]
        if 'sentiment_score' in df.columns:
            sort_options.append("æŒ‰æƒ…æ„Ÿå¾—åˆ†é™åº")
        if 'post_time' in df.columns:
            sort_options.append("æŒ‰æ—¶é—´é™åº")
            
        sort_option = st.selectbox("æ’åºæ–¹å¼:", sort_options)

        if sort_option == "æŒ‰ç‚¹èµæ•°é™åº" and 'like_count' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('like_count', ascending=False)
        elif sort_option == "æŒ‰æƒ…æ„Ÿå¾—åˆ†é™åº" and 'sentiment_score' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('sentiment_score', ascending=False)
        elif sort_option == "æŒ‰æ—¶é—´é™åº" and 'post_time' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('post_time', ascending=False)

        # åˆ†é¡µæ˜¾ç¤º
        page_size = 10
        total_pages = max(1, (len(filtered_df) // page_size) + 1)

        page_number = st.number_input("é¡µç ", min_value=1, max_value=total_pages, value=1)
        start_idx = (page_number - 1) * page_size
        end_idx = start_idx + page_size

        # æ˜¾ç¤ºè¯„è®º
        for idx, row in filtered_df.iloc[start_idx:end_idx].iterrows():
            # æ ¹æ®æƒ…æ„Ÿè®¾ç½®é¢œè‰²
            if row['sentiment_label'] == 'ç§¯æ':
                color = "ğŸŸ¢"
                border_color = "#2E8B57"
            elif row['sentiment_label'] == 'æ¶ˆæ':
                color = "ğŸ”´"
                border_color = "#DC143C"
            else:
                color = "ğŸ”µ"
                border_color = "#1E90FF"

            # æ˜¾ç¤ºè¯„è®ºå¡ç‰‡
            st.markdown(f"""
            <div style="border-left: 4px solid {border_color}; padding: 10px; margin: 10px 0; background-color: #f8f9fa;">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <strong>{color} {row['user_name'] if 'user_name' in row else 'åŒ¿åç”¨æˆ·'}</strong>
                    <span>ğŸ‘ {row['like_count'] if 'like_count' in row else 0} | æƒ…æ„Ÿ: {row['sentiment_score'] if 'sentiment_score' in row else 'N/A'}</span>
                </div>
                <p style="margin: 5px 0;">{row['content_cleaned'] if 'content_cleaned' in row else 'æ— å†…å®¹'}</p>
                <small>æ—¶é—´: {row['post_time'] if 'post_time' in row else 'æœªçŸ¥'}</small>
            </div>
            """, unsafe_allow_html=True)

    else:
        # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶æ—¶çš„å±•ç¤º
        st.info("ğŸ‘† è¯·åœ¨å·¦ä¾§ä¸Šä¼ Bç«™è¯„è®ºæ•°æ®CSVæ–‡ä»¶å¼€å§‹åˆ†æ")

        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. **å‡†å¤‡æ•°æ®**: ç¡®ä¿CSVæ–‡ä»¶åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
           - `segmented_words`: åˆ†è¯ç»“æœï¼ˆæœ€é‡è¦ï¼ï¼‰
           - `sentiment_label`: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆç§¯æ/æ¶ˆæ/ä¸­æ€§ï¼‰
           - `sentiment_score`: æƒ…æ„Ÿå¾—åˆ†ï¼ˆ0-1ï¼‰
           - `content_cleaned`: æ¸…æ´—åçš„è¯„è®ºå†…å®¹
           - `like_count`: ç‚¹èµæ•°
           - `user_name`: ç”¨æˆ·å
           - `post_time`: å‘å¸ƒæ—¶é—´

        2. **ä¸Šä¼ æ–‡ä»¶**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ CSVæ–‡ä»¶

        3. **ç”Ÿæˆè¯äº‘**: é¦–å…ˆæµ‹è¯•è¯äº‘åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ

        4. **æ¢ç´¢åˆ†æ**: æŸ¥çœ‹å„ç§å¯è§†åŒ–å›¾è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
        """)

        # æ˜¾ç¤ºåŠŸèƒ½é¢„è§ˆ
        st.header("ğŸ¯ åŠŸèƒ½é¢„è§ˆ")
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("æƒ…æ„Ÿåˆ†æ")
            st.markdown("""
            - æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
            - æƒ…æ„Ÿå¾—åˆ†ç›´æ–¹å›¾  
            - æ—¶é—´è¶‹åŠ¿åˆ†æ
            - è¯„è®ºè¯¦æƒ…æµè§ˆ
            """)

        with col2:
            st.subheader("æ–‡æœ¬åˆ†æ")
            st.markdown("""
            - åŠ¨æ€è¯äº‘ç”Ÿæˆ
            - é«˜é¢‘è¯æ±‡ç»Ÿè®¡
            - æƒ…æ„Ÿè¯æ±‡å¯¹æ¯”
            - å¤šç»´åº¦ç­›é€‰
            """)

if __name__ == "__main__":
    main()
