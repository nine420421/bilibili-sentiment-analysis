import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import jieba
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import os
import platform
import base64
import requests
from io import BytesIO
import numpy as np
from PIL import Image
import matplotlib.font_manager as fm
import tempfile

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è°ƒè¯•ä¿¡æ¯å¼€å…³
DEBUG = st.sidebar.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=True)

def debug_info(message):
    """æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯"""
    if DEBUG:
        st.sidebar.write(f"ğŸ” {message}")

def get_available_fonts():
    """è·å–æ‰€æœ‰å¯ç”¨å­—ä½“"""
    fonts = []
    try:
        for font in fm.fontManager.ttflist:
            fonts.append({
                'name': font.name,
                'path': font.fname
            })
        debug_info(f"æ‰¾åˆ° {len(fonts)} ä¸ªç³»ç»Ÿå­—ä½“")
    except Exception as e:
        debug_info(f"è·å–å­—ä½“åˆ—è¡¨å¤±è´¥: {e}")
    return fonts

def upload_custom_font():
    """ä¸Šä¼ è‡ªå®šä¹‰å­—ä½“"""
    st.sidebar.subheader("ğŸ“ ä¸Šä¼ è‡ªå®šä¹‰å­—ä½“")
    uploaded_font = st.sidebar.file_uploader("ä¸Šä¼ TTFå­—ä½“æ–‡ä»¶", type=['ttf', 'otf'], key="font_uploader")
    
    if uploaded_font is not None:
        try:
            # ä¿å­˜ä¸Šä¼ çš„å­—ä½“åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.ttf') as tmp_file:
                tmp_file.write(uploaded_font.getvalue())
                font_path = tmp_file.name
            st.sidebar.success(f"âœ… å­—ä½“ä¸Šä¼ æˆåŠŸ: {uploaded_font.name}")
            return font_path
        except Exception as e:
            st.sidebar.error(f"âŒ å­—ä½“ä¸Šä¼ å¤±è´¥: {e}")
            return None
    return None

def get_best_chinese_font():
    """è·å–æœ€ä½³ä¸­æ–‡å­—ä½“"""
    # é¦–å…ˆæ£€æŸ¥ä¸Šä¼ çš„å­—ä½“
    custom_font = upload_custom_font()
    if custom_font:
        return custom_font
    
    # æŸ¥æ‰¾ç³»ç»Ÿå­—ä½“
    chinese_keywords = ['simhei', 'microsoft', 'pingfang', 'heiti', 'stsong', 'noto', 'cjk', 'sc', 'msyh', 'simsun']
    
    fonts = get_available_fonts()
    for font in fonts:
        font_name_lower = font['name'].lower()
        if any(keyword in font_name_lower for keyword in chinese_keywords):
            debug_info(f"é€‰ä¸­å­—ä½“: {font['name']}")
            return font['path']
    
    # å¦‚æœæ²¡æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨å­—ä½“
    if fonts:
        debug_info(f"ä½¿ç”¨é»˜è®¤å­—ä½“: {fonts[0]['name']}")
        return fonts[0]['path']
    
    return None

def create_wordcloud_ultimate(word_freq, font_path, width=1200, height=600, max_words=100, colormap='viridis', background_color='white'):
    """ç»ˆæç‰ˆè¯äº‘ç”Ÿæˆ"""
    try:
        # éªŒè¯å­—ä½“æ–‡ä»¶
        if font_path and os.path.exists(font_path):
            try:
                # æµ‹è¯•å­—ä½“æ˜¯å¦å¯ç”¨
                test_font = fm.FontProperties(fname=font_path)
                debug_info(f"å­—ä½“éªŒè¯é€šè¿‡: {os.path.basename(font_path)}")
            except Exception as e:
                debug_info(f"å­—ä½“éªŒè¯å¤±è´¥: {e}")
                # ä½¿ç”¨é»˜è®¤å­—ä½“
                font_path = None
        
        # è¯äº‘é…ç½®
        wc_config = {
            'width': width,
            'height': height,
            'background_color': background_color,
            'max_words': max_words,
            'colormap': colormap,
            'relative_scaling': 0.4,
            'random_state': 42,
            'prefer_horizontal': 0.8,
            'scale': 3,  # æé«˜åˆ†è¾¨ç‡
            'min_font_size': 8,
            'max_font_size': 150,
            'collocations': False,
            'normalize_plurals': False,
            'mode': 'RGBA'
        }
        
        # å¦‚æœæœ‰å¯ç”¨å­—ä½“å°±ä½¿ç”¨
        if font_path:
            wc_config['font_path'] = font_path
        
        # ç”Ÿæˆè¯äº‘
        wc = WordCloud(**wc_config)
        wordcloud = wc.generate_from_frequencies(word_freq)
        
        debug_info("è¯äº‘ç”ŸæˆæˆåŠŸ")
        return wordcloud
        
    except Exception as e:
        debug_info(f"è¯äº‘ç”Ÿæˆé”™è¯¯: {e}")
        return None

def create_wordcloud_image_manual(word_freq, width=1200, height=600, max_words=100, colormap='viridis', background_color='white'):
    """æ‰‹åŠ¨åˆ›å»ºè¯äº‘å›¾ç‰‡ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    try:
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(width/100, height/100), dpi=100)
        
        # è®¾ç½®èƒŒæ™¯
        fig.patch.set_facecolor(background_color)
        ax.set_facecolor(background_color)
        
        # è·å–é¢œè‰²æ˜ å°„
        cmap = plt.cm.get_cmap(colormap)
        
        # è®¡ç®—ä½ç½®å’Œå¤§å°
        words = list(word_freq.keys())[:max_words]
        counts = list(word_freq.values())[:max_words]
        
        # å½’ä¸€åŒ–è®¡æ•°ç”¨äºå­—ä½“å¤§å°
        max_count = max(counts)
        min_count = min(counts)
        
        if max_count == min_count:
            sizes = [50] * len(words)  # æ‰€æœ‰è¯ç›¸åŒå¤§å°
        else:
            sizes = [20 + 80 * (count - min_count) / (max_count - min_count) for count in counts]
        
        # ç®€å•å¸ƒå±€ç®—æ³•
        x_positions = []
        y_positions = []
        
        for i in range(len(words)):
            # ç®€å•çš„ç½‘æ ¼å¸ƒå±€
            row = i // 8
            col = i % 8
            x = col * (width / 8) + (width / 16)
            y = height - (row * (height / (len(words)//8 + 1)) + (height / ((len(words)//8 + 1)*2)))
            x_positions.append(x)
            y_positions.append(y)
        
        # ç»˜åˆ¶æ–‡å­—
        for i, (word, x, y, size) in enumerate(zip(words, x_positions, y_positions, sizes)):
            color = cmap(i / len(words))
            ax.text(x, y, word, fontsize=size, 
                   color=color, ha='center', va='center',
                   fontproperties=fm.FontProperties(fname=get_best_chinese_font()))
        
        ax.set_xlim(0, width)
        ax.set_ylim(0, height)
        ax.axis('off')
        
        return fig
        
    except Exception as e:
        debug_info(f"æ‰‹åŠ¨è¯äº‘ç”Ÿæˆå¤±è´¥: {e}")
        return None

def display_word_frequency(word_freq, title="é«˜é¢‘è¯æ±‡"):
    """æ˜¾ç¤ºè¯é¢‘çš„å¤‡ç”¨æ–¹æ¡ˆ"""
    top_words = word_freq.most_common(20)
    
    if top_words:
        words = [word for word, _ in top_words]
        counts = [count for _, count in top_words]
        
        fig, ax = plt.subplots(figsize=(12, 8))
        bars = ax.barh(range(len(words)), counts, color='lightblue')
        ax.set_yticks(range(len(words)))
        ax.set_yticklabels(words, fontsize=12)
        ax.set_xlabel('å‡ºç°æ¬¡æ•°', fontsize=14)
        ax.set_title(title, fontsize=16, pad=20)
        
        # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
        for i, (bar, count) in enumerate(zip(bars, counts)):
            ax.text(count + 0.1, bar.get_y() + bar.get_height()/2, 
                   str(count), ha='left', va='center', fontsize=10)
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close(fig)

def get_words_from_segmented(segmented_str):
    """ä»åˆ†è¯å­—ç¬¦ä¸²ä¸­æå–è¯æ±‡"""
    if pd.isna(segmented_str) or not isinstance(segmented_str, str):
        return []
    
    try:
        clean_str = segmented_str.strip()
        
        # å¤„ç†åˆ—è¡¨æ ¼å¼
        if clean_str.startswith('[') and clean_str.endswith(']'):
            content = clean_str[1:-1].replace("'", "").replace('"', '')
            words = [word.strip() for word in content.split(',')]
        else:
            words = clean_str.split()
        
        # è¿‡æ»¤
        filtered_words = []
        for word in words:
            word_clean = word.strip()
            if (len(word_clean) > 0 and 
                not word_clean.isspace() and
                word_clean not in [' ', '', '\\n', '\\t']):
                filtered_words.append(word_clean)
        
        return filtered_words
        
    except Exception as e:
        debug_info(f"åˆ†è¯è§£æé”™è¯¯: {e}")
        return []

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="Bç«™è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide"
)

def main():
    # æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ¯ Bç«™è§†é¢‘è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ å’Œè®¾ç½®
    st.sidebar.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ è¯„è®ºæ•°æ®CSVæ–‡ä»¶", type=['csv'])

    if uploaded_file is not None:
        # è¯»å–æ•°æ®
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼Œå…± {len(df)} è¡Œ")
        except Exception as e:
            st.error(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
            return
        
        # æ•°æ®é¢„å¤„ç†
        if 'post_time' in df.columns:
            df['post_time'] = pd.to_datetime(df['post_time'], errors='coerce')

        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        st.header("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æ€»è¯„è®ºæ•°", len(df))
        with col2:
            positive_count = len(df[df['sentiment_label'] == 'ç§¯æ'])
            st.metric("ç§¯æè¯„è®º", positive_count)
        with col3:
            negative_count = len(df[df['sentiment_label'] == 'æ¶ˆæ'])
            st.metric("æ¶ˆæè¯„è®º", negative_count)
        with col4:
            neutral_count = len(df[df['sentiment_label'] == 'ä¸­æ€§'])
            st.metric("ä¸­æ€§è¯„è®º", neutral_count)

        # æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
        st.header("ğŸ­ æƒ…æ„Ÿåˆ†å¸ƒåˆ†æ")
        col1, col2 = st.columns(2)

        with col1:
            sentiment_counts = df['sentiment_label'].value_counts()
            fig_pie = px.pie(
                values=sentiment_counts.values,
                names=sentiment_counts.index,
                title='è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ',
                color=sentiment_counts.index,
                color_discrete_map={'ç§¯æ': '#2E8B57', 'æ¶ˆæ': '#DC143C', 'ä¸­æ€§': '#1E90FF'}
            )
            st.plotly_chart(fig_pie, use_container_width=True)

        with col2:
            if 'sentiment_score' in df.columns:
                fig_hist = px.histogram(
                    df, x='sentiment_score',
                    title='æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ',
                    nbins=20,
                    color_discrete_sequence=['#636EFA']
                )
                fig_hist.add_vline(x=0.5, line_dash="dash", line_color="red")
                st.plotly_chart(fig_hist, use_container_width=True)

        # æ—¶é—´è¶‹åŠ¿åˆ†æ
        st.header("ğŸ“ˆ è¯„è®ºæ—¶é—´è¶‹åŠ¿")
        if 'post_time' in df.columns:
            daily_stats = df.groupby(df['post_time'].dt.date).agg({
                'sentiment_score': 'mean',
                'comment_id': 'count'
            }).reset_index()

            col1, col2 = st.columns(2)

            with col1:
                fig_trend = px.line(
                    daily_stats, x='post_time', y='sentiment_score',
                    title='æ¯æ—¥å¹³å‡æƒ…æ„Ÿå¾—åˆ†è¶‹åŠ¿',
                    labels={'sentiment_score': 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†', 'post_time': 'æ—¥æœŸ'}
                )
                st.plotly_chart(fig_trend, use_container_width=True)

            with col2:
                fig_count = px.bar(
                    daily_stats, x='post_time', y='comment_id',
                    title='æ¯æ—¥è¯„è®ºæ•°é‡',
                    labels={'comment_id': 'è¯„è®ºæ•°é‡', 'post_time': 'æ—¥æœŸ'}
                )
                st.plotly_chart(fig_count, use_container_width=True)
        else:
            st.info("æ•°æ®ä¸­æ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œæ— æ³•æ˜¾ç¤ºæ—¶é—´è¶‹åŠ¿")

        # è¯äº‘åˆ†æ
        st.header("â˜ï¸ è¯äº‘åˆ†æ")
        
        # æ˜¾ç¤ºå¯ç”¨å­—ä½“ä¿¡æ¯
        if DEBUG:
            fonts = get_available_fonts()
            chinese_fonts = [f for f in fonts if any(kw in f['name'].lower() for kw in ['simhei', 'microsoft', 'pingfang', 'heiti'])]
            st.sidebar.info(f"æ‰¾åˆ° {len(chinese_fonts)} ä¸ªä¸­æ–‡å­—ä½“")

        # æƒ…æ„Ÿé€‰æ‹©
        sentiment_option = st.selectbox(
            "é€‰æ‹©æƒ…æ„Ÿç±»å‹æŸ¥çœ‹è¯äº‘:",
            ["å…¨éƒ¨è¯„è®º", "ç§¯æè¯„è®º", "æ¶ˆæè¯„è®º", "ä¸­æ€§è¯„è®º"],
            key="sentiment_selector"
        )

        # è¯äº‘è®¾ç½®é€‰é¡¹
        col1, col2, col3 = st.columns(3)
        with col1:
            max_words = st.slider("æœ€å¤§è¯æ±‡æ•°é‡", 30, 150, 80, key="max_words_slider")
        with col2:
            background_color = st.selectbox("èƒŒæ™¯é¢œè‰²", 
                ["white", "black", "#f0f0f0", "#f8f9fa"], key="bg_color_selector")
        with col3:
            colormap_option = st.selectbox("é¢œè‰²æ–¹æ¡ˆ", 
                ["viridis", "plasma", "inferno", "spring", "summer", "autumn", "winter"], 
                key="colormap_selector")

        # ç”Ÿæˆæ¨¡å¼é€‰æ‹©
        generate_mode = st.radio("ç”Ÿæˆæ¨¡å¼:", 
                                ["è‡ªåŠ¨è¯äº‘", "æ‰‹åŠ¨å¸ƒå±€"], 
                                help="è‡ªåŠ¨è¯äº‘ä½¿ç”¨wordcloudåº“ï¼Œæ‰‹åŠ¨å¸ƒå±€ä½¿ç”¨matplotlibç›´æ¥ç»˜åˆ¶")

        # ç”Ÿæˆè¯äº‘
        if st.button("ç”Ÿæˆè¯äº‘", type="primary", key="generate_wordcloud"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯äº‘..."):
                # æ ¹æ®é€‰æ‹©è¿‡æ»¤æ•°æ®
                if sentiment_option == "å…¨éƒ¨è¯„è®º":
                    target_df = df
                elif sentiment_option == "ç§¯æè¯„è®º":
                    target_df = df[df['sentiment_label'] == 'ç§¯æ']
                elif sentiment_option == "æ¶ˆæè¯„è®º":
                    target_df = df[df['sentiment_label'] == 'æ¶ˆæ']
                else:
                    target_df = df[df['sentiment_label'] == 'ä¸­æ€§']

                debug_info(f"ç›®æ ‡æ•°æ®è¡Œæ•°: {len(target_df)}")
                
                if len(target_df) == 0:
                    st.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ° {sentiment_option} çš„æ•°æ®")
                    return

                # å‡†å¤‡æ–‡æœ¬æ•°æ®
                all_words = []
                for seg_text in target_df['segmented_words']:
                    words = get_words_from_segmented(seg_text)
                    all_words.extend(words)

                if all_words:
                    # ç»Ÿè®¡è¯é¢‘
                    word_freq = Counter(all_words)
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.success(f"âœ… æˆåŠŸæå– {len(all_words)} ä¸ªè¯æ±‡ï¼Œ{len(word_freq)} ä¸ªä¸åŒè¯æ±‡")
                    
                    # æ˜¾ç¤ºå‰10ä¸ªé«˜é¢‘è¯
                    top_10 = word_freq.most_common(10)
                    top_words_str = "ã€".join([f"{word}({count})" for word, count in top_10])
                    st.info(f"ğŸ“Š å‰10ä¸ªé«˜é¢‘è¯: {top_words_str}")
                    
                    # è·å–å­—ä½“
                    font_path = get_best_chinese_font()
                    
                    if font_path:
                        st.success(f"ğŸ¨ ä½¿ç”¨å­—ä½“: {os.path.basename(font_path)}")
                    else:
                        st.warning("âš ï¸ ä½¿ç”¨é»˜è®¤å­—ä½“")

                    # æ ¹æ®æ¨¡å¼ç”Ÿæˆè¯äº‘
                    if generate_mode == "è‡ªåŠ¨è¯äº‘":
                        wordcloud = create_wordcloud_ultimate(
                            word_freq, 
                            font_path, 
                            max_words=max_words,
                            colormap=colormap_option,
                            background_color=background_color
                        )

                        if wordcloud is not None:
                            # æ˜¾ç¤ºè¯äº‘
                            fig, ax = plt.subplots(figsize=(16, 9))
                            ax.imshow(wordcloud, interpolation='bilinear')
                            ax.axis('off')
                            ax.set_title(f'{sentiment_option} - è¯äº‘å›¾', 
                                       fontsize=22, pad=20, fontweight='bold')
                            fig.patch.set_facecolor(background_color)
                            st.pyplot(fig)
                            plt.close(fig)
                            st.success("ğŸ‰ è‡ªåŠ¨è¯äº‘ç”ŸæˆæˆåŠŸï¼")
                        else:
                            st.error("âŒ è‡ªåŠ¨è¯äº‘ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨å¸ƒå±€")
                            generate_mode = "æ‰‹åŠ¨å¸ƒå±€"

                    if generate_mode == "æ‰‹åŠ¨å¸ƒå±€":
                        st.info("ğŸ”„ ä½¿ç”¨æ‰‹åŠ¨å¸ƒå±€ç”Ÿæˆè¯äº‘")
                        fig = create_wordcloud_image_manual(
                            word_freq,
                            max_words=max_words,
                            colormap=colormap_option,
                            background_color=background_color
                        )
                        
                        if fig is not None:
                            st.pyplot(fig)
                            plt.close(fig)
                            st.success("ğŸ‰ æ‰‹åŠ¨å¸ƒå±€è¯äº‘ç”ŸæˆæˆåŠŸï¼")
                        else:
                            st.error("âŒ æ‰€æœ‰è¯äº‘ç”Ÿæˆæ–¹æ¡ˆéƒ½å¤±è´¥äº†")
                            st.info("ğŸ”„ æ˜¾ç¤ºè¯é¢‘æ¡å½¢å›¾ä½œä¸ºæ›¿ä»£")
                            display_word_frequency(word_freq, f'{sentiment_option} - é«˜é¢‘è¯æ±‡')

                    # æ˜¾ç¤ºé«˜é¢‘è¯è¡¨æ ¼
                    st.subheader("ğŸ“‹ é«˜é¢‘è¯æ±‡TOP20")
                    top_words = word_freq.most_common(20)
                    word_df = pd.DataFrame(top_words, columns=['è¯æ±‡', 'å‡ºç°æ¬¡æ•°'])
                    st.dataframe(word_df, use_container_width=True, height=400)

                else:
                    st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„è¯æ±‡æ•°æ®æ¥ç”Ÿæˆè¯äº‘")

        # è¯„è®ºè¯¦æƒ…æŸ¥çœ‹ï¼ˆä¿æŒä¸å˜ï¼‰
        # ... è¿™é‡Œä¿æŒåŸæœ‰çš„è¯„è®ºè¯¦æƒ…ä»£ç 

    else:
        # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶æ—¶çš„å±•ç¤º
        st.info("ğŸ‘† è¯·åœ¨å·¦ä¾§ä¸Šä¼ Bç«™è¯„è®ºæ•°æ®CSVæ–‡ä»¶å¼€å§‹åˆ†æ")

        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. **å‡†å¤‡æ•°æ®**: ç¡®ä¿CSVæ–‡ä»¶åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
           - `segmented_words`: åˆ†è¯ç»“æœ
           - `sentiment_label`: æƒ…æ„Ÿæ ‡ç­¾
           - å…¶ä»–å¯é€‰å­—æ®µ

        2. **ä¸Šä¼ æ–‡ä»¶**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ CSVæ–‡ä»¶

        3. **ä¸Šä¼ å­—ä½“(å¯é€‰)**: å¦‚æœè¯äº‘ä¸æ˜¾ç¤ºæ–‡å­—ï¼Œå¯ä»¥ä¸Šä¼ TTFå­—ä½“æ–‡ä»¶

        4. **ç”Ÿæˆè¯äº‘**: é€‰æ‹©æ‰‹åŠ¨å¸ƒå±€æ¨¡å¼ç¡®ä¿æ˜¾ç¤ºæ–‡å­—
        """)

if __name__ == "__main__":
    main()
