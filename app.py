import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import jieba
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import os
import platform
import base64
import requests
from io import BytesIO
import numpy as np
from PIL import Image
import matplotlib.font_manager as fm

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è°ƒè¯•ä¿¡æ¯å¼€å…³
DEBUG = st.sidebar.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=True)

def debug_info(message):
    """æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯"""
    if DEBUG:
        st.sidebar.write(f"ğŸ” {message}")

def get_chinese_font():
    """è·å–ä¸­æ–‡å­—ä½“ - ç®€åŒ–ç‰ˆæœ¬"""
    try:
        # æ–¹æ¡ˆ1: ç›´æ¥ä½¿ç”¨matplotlibçš„å­—ä½“ç®¡ç†å™¨
        chinese_fonts = []
        for font in fm.fontManager.ttflist:
            font_name = font.name.lower()
            if any(keyword in font_name for keyword in ['simhei', 'microsoft', 'pingfang', 'heiti', 'stsong', 'noto', 'cjk', 'sc']):
                chinese_fonts.append(font.fname)
        
        if chinese_fonts:
            debug_info(f"æ‰¾åˆ° {len(chinese_fonts)} ä¸ªä¸­æ–‡å­—ä½“")
            return chinese_fonts[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å­—ä½“
        
        # æ–¹æ¡ˆ2: å¸¸è§å­—ä½“è·¯å¾„
        common_paths = [
            # Windows
            "C:/Windows/Fonts/simhei.ttf",
            "C:/Windows/Fonts/msyh.ttc",
            # Linux
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",
        ]
        
        for path in common_paths:
            if os.path.exists(path):
                debug_info(f"æ‰¾åˆ°ç³»ç»Ÿå­—ä½“: {path}")
                return path
                
    except Exception as e:
        debug_info(f"å­—ä½“æœç´¢é”™è¯¯: {e}")
    
    debug_info("ä½¿ç”¨é»˜è®¤å­—ä½“")
    return None

def create_simple_wordcloud(word_freq, font_path, width=800, height=400, max_words=100, colormap='viridis', background_color='white'):
    """åˆ›å»ºè¯äº‘çš„ç®€åŒ–ç‰ˆæœ¬"""
    try:
        # åŸºæœ¬é…ç½®
        wc = WordCloud(
            font_path=font_path,
            width=width,
            height=height,
            background_color=background_color,
            max_words=max_words,
            colormap=colormap,
            relative_scaling=0.5,
            random_state=42,
            prefer_horizontal=0.9,  # æ›´å¤šæ°´å¹³æ–‡å­—
            scale=2,
            min_font_size=10,
            max_font_size=150,
            stopwords=None,
            collocations=False,  # ç¦ç”¨è¯ç»„ç»„åˆ
            normalize_plurals=False
        )
        
        # ç”Ÿæˆè¯äº‘
        wordcloud = wc.generate_from_frequencies(word_freq)
        debug_info("è¯äº‘ç”ŸæˆæˆåŠŸ")
        return wordcloud
        
    except Exception as e:
        debug_info(f"è¯äº‘ç”Ÿæˆå¤±è´¥: {e}")
        return None

def test_font_rendering():
    """æµ‹è¯•å­—ä½“æ¸²æŸ“"""
    try:
        fig, ax = plt.subplots(figsize=(8, 2))
        ax.text(0.5, 0.5, "ä¸­æ–‡æµ‹è¯•å­—ä½“æ¸²æŸ“", 
               fontsize=20, ha='center', va='center')
        ax.axis('off')
        st.pyplot(fig)
        plt.close(fig)
        return True
    except Exception as e:
        debug_info(f"å­—ä½“æ¸²æŸ“æµ‹è¯•å¤±è´¥: {e}")
        return False

def display_word_frequency(word_freq, title="é«˜é¢‘è¯æ±‡"):
    """æ˜¾ç¤ºè¯é¢‘çš„å¤‡ç”¨æ–¹æ¡ˆ"""
    top_words = word_freq.most_common(20)
    
    if top_words:
        words = [word for word, _ in top_words]
        counts = [count for _, count in top_words]
        
        fig, ax = plt.subplots(figsize=(12, 8))
        bars = ax.barh(range(len(words)), counts)
        ax.set_yticks(range(len(words)))
        ax.set_yticklabels(words, fontsize=12)
        ax.set_xlabel('å‡ºç°æ¬¡æ•°', fontsize=14)
        ax.set_title(title, fontsize=16, pad=20)
        
        # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
        for i, (bar, count) in enumerate(zip(bars, counts)):
            ax.text(count + 0.1, bar.get_y() + bar.get_height()/2, 
                   str(count), ha='left', va='center', fontsize=10)
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close(fig)

def get_words_from_segmented(segmented_str):
    """ä»åˆ†è¯å­—ç¬¦ä¸²ä¸­æå–è¯æ±‡"""
    if pd.isna(segmented_str) or not isinstance(segmented_str, str):
        return []
    
    try:
        clean_str = segmented_str.strip()
        
        # å¤„ç†åˆ—è¡¨æ ¼å¼
        if clean_str.startswith('[') and clean_str.endswith(']'):
            # ç§»é™¤æ–¹æ‹¬å·å’Œå¼•å·
            content = clean_str[1:-1].replace("'", "").replace('"', '')
            words = [word.strip() for word in content.split(',')]
        else:
            # ç›´æ¥åˆ†å‰²
            words = clean_str.split()
        
        # è¿‡æ»¤
        filtered_words = []
        for word in words:
            word_clean = word.strip()
            if (len(word_clean) > 1 and 
                not word_clean.isdigit() and 
                not word_clean.isspace() and
                word_clean not in [' ', '', '\\n', '\\t']):
                filtered_words.append(word_clean)
        
        debug_info(f"è§£æå‡º {len(filtered_words)} ä¸ªè¯æ±‡")
        return filtered_words
        
    except Exception as e:
        debug_info(f"åˆ†è¯è§£æé”™è¯¯: {e}")
        return []

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="Bç«™è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide"
)

def main():
    # æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ¯ Bç«™è§†é¢‘è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ å’Œè®¾ç½®
    st.sidebar.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ è¯„è®ºæ•°æ®CSVæ–‡ä»¶", type=['csv'])

    if uploaded_file is not None:
        # è¯»å–æ•°æ®
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼Œå…± {len(df)} è¡Œ")
        except Exception as e:
            st.error(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
            return
        
        # æ•°æ®é¢„å¤„ç†
        if 'post_time' in df.columns:
            df['post_time'] = pd.to_datetime(df['post_time'], errors='coerce')

        # æ•°æ®æ£€æŸ¥
        st.sidebar.subheader("ğŸ“‹ æ•°æ®æ£€æŸ¥")
        st.sidebar.write(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        
        # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['segmented_words', 'sentiment_label']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            st.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            st.info("è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å« 'segmented_words' å’Œ 'sentiment_label' åˆ—")
            return

        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        st.header("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æ€»è¯„è®ºæ•°", len(df))
        with col2:
            positive_count = len(df[df['sentiment_label'] == 'ç§¯æ'])
            st.metric("ç§¯æè¯„è®º", positive_count)
        with col3:
            negative_count = len(df[df['sentiment_label'] == 'æ¶ˆæ'])
            st.metric("æ¶ˆæè¯„è®º", negative_count)
        with col4:
            neutral_count = len(df[df['sentiment_label'] == 'ä¸­æ€§'])
            st.metric("ä¸­æ€§è¯„è®º", neutral_count)

        # è¯äº‘åˆ†æ
        st.header("â˜ï¸ è¯äº‘åˆ†æ")

        # å­—ä½“æµ‹è¯•
        if st.sidebar.checkbox("æµ‹è¯•å­—ä½“æ¸²æŸ“"):
            st.sidebar.subheader("å­—ä½“æ¸²æŸ“æµ‹è¯•")
            test_font_rendering()

        # æƒ…æ„Ÿé€‰æ‹©
        sentiment_option = st.selectbox(
            "é€‰æ‹©æƒ…æ„Ÿç±»å‹æŸ¥çœ‹è¯äº‘:",
            ["å…¨éƒ¨è¯„è®º", "ç§¯æè¯„è®º", "æ¶ˆæè¯„è®º", "ä¸­æ€§è¯„è®º"]
        )

        # è¯äº‘è®¾ç½®é€‰é¡¹
        col1, col2, col3 = st.columns(3)
        with col1:
            max_words = st.slider("æœ€å¤§è¯æ±‡æ•°é‡", 50, 200, 100)
        with col2:
            background_color = st.selectbox("èƒŒæ™¯é¢œè‰²", 
                ["white", "black", "gray", "lightblue", "lightgreen"])
        with col3:
            colormap_option = st.selectbox("é¢œè‰²æ–¹æ¡ˆ", 
                ["viridis", "plasma", "inferno", "spring", "summer", "autumn", "winter", "cool", "hot"])

        # ç”Ÿæˆè¯äº‘
        if st.button("ç”Ÿæˆè¯äº‘", type="primary"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆè¯äº‘..."):
                # æ ¹æ®é€‰æ‹©è¿‡æ»¤æ•°æ®
                if sentiment_option == "å…¨éƒ¨è¯„è®º":
                    target_df = df
                elif sentiment_option == "ç§¯æè¯„è®º":
                    target_df = df[df['sentiment_label'] == 'ç§¯æ']
                elif sentiment_option == "æ¶ˆæè¯„è®º":
                    target_df = df[df['sentiment_label'] == 'æ¶ˆæ']
                else:
                    target_df = df[df['sentiment_label'] == 'ä¸­æ€§']

                debug_info(f"ç›®æ ‡æ•°æ®è¡Œæ•°: {len(target_df)}")
                
                if len(target_df) == 0:
                    st.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ° {sentiment_option} çš„æ•°æ®")
                    return

                # å‡†å¤‡æ–‡æœ¬æ•°æ®
                all_words = []
                for seg_text in target_df['segmented_words']:
                    words = get_words_from_segmented(seg_text)
                    all_words.extend(words)

                if all_words:
                    # ç»Ÿè®¡è¯é¢‘
                    word_freq = Counter(all_words)
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.success(f"âœ… æˆåŠŸæå– {len(all_words)} ä¸ªè¯æ±‡ï¼Œ{len(word_freq)} ä¸ªä¸åŒè¯æ±‡")
                    
                    # æ˜¾ç¤ºå‰10ä¸ªé«˜é¢‘è¯ï¼ˆæ ¼å¼åŒ–çš„ï¼‰
                    top_10 = word_freq.most_common(10)
                    top_words_str = "ã€".join([f"{word}({count})" for word, count in top_10])
                    st.info(f"ğŸ“Š å‰10ä¸ªé«˜é¢‘è¯: {top_words_str}")
                    
                    # è·å–å­—ä½“
                    font_path = get_chinese_font()
                    
                    if font_path:
                        st.success(f"ğŸ¨ ä½¿ç”¨å­—ä½“: {os.path.basename(font_path)}")
                    else:
                        st.warning("âš ï¸ ä½¿ç”¨é»˜è®¤å­—ä½“")

                    # åˆ›å»ºè¯äº‘
                    wordcloud = create_simple_wordcloud(
                        word_freq, 
                        font_path, 
                        max_words=max_words,
                        colormap=colormap_option,
                        background_color=background_color
                    )

                    if wordcloud is not None:
                        # æ˜¾ç¤ºè¯äº‘
                        fig, ax = plt.subplots(figsize=(16, 8))
                        
                        # æ˜¾ç¤ºè¯äº‘å›¾åƒ
                        ax.imshow(wordcloud, interpolation='bilinear')
                        ax.axis('off')
                        ax.set_title(f'{sentiment_option} - è¯äº‘å›¾', 
                                   fontsize=20, pad=20, fontweight='bold')
                        
                        # è®¾ç½®èƒŒæ™¯é¢œè‰²
                        fig.patch.set_facecolor(background_color)
                        ax.set_facecolor(background_color)
                        
                        st.pyplot(fig)
                        plt.close(fig)
                        st.success("ğŸ‰ è¯äº‘ç”ŸæˆæˆåŠŸï¼")
                        
                        # æ˜¾ç¤ºè¯äº‘ä¿¡æ¯
                        st.info(f"""
                        **è¯äº‘ä¿¡æ¯:**
                        - èƒŒæ™¯é¢œè‰²: {background_color}
                        - é¢œè‰²æ–¹æ¡ˆ: {colormap_option}
                        - æœ€å¤§è¯æ±‡æ•°: {max_words}
                        - å®é™…æ˜¾ç¤ºè¯æ±‡: {len(wordcloud.words_)}
                        """)
                        
                    else:
                        st.error("âŒ è¯äº‘ç”Ÿæˆå¤±è´¥")
                        st.info("ğŸ”„ æ˜¾ç¤ºè¯é¢‘æ¡å½¢å›¾ä½œä¸ºæ›¿ä»£")
                        display_word_frequency(word_freq, f'{sentiment_option} - é«˜é¢‘è¯æ±‡')

                    # æ˜¾ç¤ºé«˜é¢‘è¯è¡¨æ ¼
                    st.subheader("ğŸ“‹ é«˜é¢‘è¯æ±‡TOP20")
                    top_words = word_freq.most_common(20)
                    
                    # åˆ›å»ºæ•°æ®æ¡†æ˜¾ç¤º
                    word_df = pd.DataFrame(top_words, columns=['è¯æ±‡', 'å‡ºç°æ¬¡æ•°'])
                    st.dataframe(word_df, use_container_width=True, height=400)

                else:
                    st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„è¯æ±‡æ•°æ®æ¥ç”Ÿæˆè¯äº‘")
                    st.info("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ•°æ®ä¸­çš„ 'segmented_words' åˆ—æ ¼å¼æ˜¯å¦æ­£ç¡®")

        # å…¶ä»–åˆ†æéƒ¨åˆ†...
        # æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
        st.header("ğŸ­ æƒ…æ„Ÿåˆ†å¸ƒåˆ†æ")
        col1, col2 = st.columns(2)

        with col1:
            sentiment_counts = df['sentiment_label'].value_counts()
            fig_pie = px.pie(
                values=sentiment_counts.values,
                names=sentiment_counts.index,
                title='è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ',
                color=sentiment_counts.index,
                color_discrete_map={'ç§¯æ': '#2E8B57', 'æ¶ˆæ': '#DC143C', 'ä¸­æ€§': '#1E90FF'}
            )
            st.plotly_chart(fig_pie, use_container_width=True)

        with col2:
            if 'sentiment_score' in df.columns:
                fig_hist = px.histogram(
                    df, x='sentiment_score',
                    title='æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ',
                    nbins=20,
                    color_discrete_sequence=['#636EFA']
                )
                fig_hist.add_vline(x=0.5, line_dash="dash", line_color="red")
                st.plotly_chart(fig_hist, use_container_width=True)

        # æ—¶é—´è¶‹åŠ¿åˆ†æ
        st.header("ğŸ“ˆ è¯„è®ºæ—¶é—´è¶‹åŠ¿")
        if 'post_time' in df.columns:
            daily_stats = df.groupby(df['post_time'].dt.date).agg({
                'sentiment_score': 'mean',
                'comment_id': 'count'
            }).reset_index()

            col1, col2 = st.columns(2)

            with col1:
                fig_trend = px.line(
                    daily_stats, x='post_time', y='sentiment_score',
                    title='æ¯æ—¥å¹³å‡æƒ…æ„Ÿå¾—åˆ†è¶‹åŠ¿',
                    labels={'sentiment_score': 'å¹³å‡æƒ…æ„Ÿå¾—åˆ†', 'post_time': 'æ—¥æœŸ'}
                )
                st.plotly_chart(fig_trend, use_container_width=True)

            with col2:
                fig_count = px.bar(
                    daily_stats, x='post_time', y='comment_id',
                    title='æ¯æ—¥è¯„è®ºæ•°é‡',
                    labels={'comment_id': 'è¯„è®ºæ•°é‡', 'post_time': 'æ—¥æœŸ'}
                )
                st.plotly_chart(fig_count, use_container_width=True)

        # è¯„è®ºè¯¦æƒ…æŸ¥çœ‹
        st.header("ğŸ’¬ è¯„è®ºè¯¦æƒ…æµè§ˆ")

        # æƒ…æ„Ÿç­›é€‰
        sentiment_filter = st.multiselect(
            "ç­›é€‰æƒ…æ„Ÿç±»å‹:",
            options=['ç§¯æ', 'æ¶ˆæ', 'ä¸­æ€§'],
            default=['ç§¯æ', 'æ¶ˆæ', 'ä¸­æ€§']
        )

        # ç‚¹èµæ•°èŒƒå›´ç­›é€‰
        min_likes = 0
        max_likes = 100
        if 'like_count' in df.columns:
            min_likes = int(df['like_count'].min())
            max_likes = int(df['like_count'].max())
            
            min_likes, max_likes = st.slider(
                "ç‚¹èµæ•°èŒƒå›´:",
                min_value=min_likes,
                max_value=max_likes,
                value=(0, max_likes)
            )

        # åº”ç”¨ç­›é€‰
        filtered_df = df[df['sentiment_label'].isin(sentiment_filter)]
        
        if 'like_count' in df.columns:
            filtered_df = filtered_df[
                (filtered_df['like_count'] >= min_likes) & 
                (filtered_df['like_count'] <= max_likes)
            ]

        # æ˜¾ç¤ºç­›é€‰åçš„è¯„è®º
        st.subheader(f"ç­›é€‰ç»“æœ: {len(filtered_df)} æ¡è¯„è®º")

        # æ’åºé€‰é¡¹
        sort_options = ["æŒ‰ç‚¹èµæ•°é™åº"]
        if 'sentiment_score' in df.columns:
            sort_options.append("æŒ‰æƒ…æ„Ÿå¾—åˆ†é™åº")
        if 'post_time' in df.columns:
            sort_options.append("æŒ‰æ—¶é—´é™åº")
            
        sort_option = st.selectbox("æ’åºæ–¹å¼:", sort_options)

        if sort_option == "æŒ‰ç‚¹èµæ•°é™åº" and 'like_count' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('like_count', ascending=False)
        elif sort_option == "æŒ‰æƒ…æ„Ÿå¾—åˆ†é™åº" and 'sentiment_score' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('sentiment_score', ascending=False)
        elif sort_option == "æŒ‰æ—¶é—´é™åº" and 'post_time' in filtered_df.columns:
            filtered_df = filtered_df.sort_values('post_time', ascending=False)

        # åˆ†é¡µæ˜¾ç¤º
        page_size = 10
        total_pages = max(1, (len(filtered_df) // page_size) + 1)

        page_number = st.number_input("é¡µç ", min_value=1, max_value=total_pages, value=1)
        start_idx = (page_number - 1) * page_size
        end_idx = start_idx + page_size

        # æ˜¾ç¤ºè¯„è®º
        for idx, row in filtered_df.iloc[start_idx:end_idx].iterrows():
            # æ ¹æ®æƒ…æ„Ÿè®¾ç½®é¢œè‰²
            if row['sentiment_label'] == 'ç§¯æ':
                color = "ğŸŸ¢"
                border_color = "#2E8B57"
            elif row['sentiment_label'] == 'æ¶ˆæ':
                color = "ğŸ”´"
                border_color = "#DC143C"
            else:
                color = "ğŸ”µ"
                border_color = "#1E90FF"

            # æ˜¾ç¤ºè¯„è®ºå¡ç‰‡
            st.markdown(f"""
            <div style="border-left: 4px solid {border_color}; padding: 10px; margin: 10px 0; background-color: #f8f9fa;">
                <div style="display: flex; justify-content: space-between; align-items: center;">
                    <strong>{color} {row['user_name'] if 'user_name' in row else 'åŒ¿åç”¨æˆ·'}</strong>
                    <span>ğŸ‘ {row['like_count'] if 'like_count' in row else 0} | æƒ…æ„Ÿ: {row['sentiment_score'] if 'sentiment_score' in row else 'N/A'}</span>
                </div>
                <p style="margin: 5px 0;">{row['content_cleaned'] if 'content_cleaned' in row else 'æ— å†…å®¹'}</p>
                <small>æ—¶é—´: {row['post_time'] if 'post_time' in row else 'æœªçŸ¥'}</small>
            </div>
            """, unsafe_allow_html=True)

    else:
        # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶æ—¶çš„å±•ç¤º
        st.info("ğŸ‘† è¯·åœ¨å·¦ä¾§ä¸Šä¼ Bç«™è¯„è®ºæ•°æ®CSVæ–‡ä»¶å¼€å§‹åˆ†æ")

        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. **å‡†å¤‡æ•°æ®**: ç¡®ä¿CSVæ–‡ä»¶åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
           - `segmented_words`: åˆ†è¯ç»“æœï¼ˆæœ€é‡è¦ï¼ï¼‰
           - `sentiment_label`: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆç§¯æ/æ¶ˆæ/ä¸­æ€§ï¼‰
           - `sentiment_score`: æƒ…æ„Ÿå¾—åˆ†ï¼ˆ0-1ï¼‰
           - `content_cleaned`: æ¸…æ´—åçš„è¯„è®ºå†…å®¹
           - `like_count`: ç‚¹èµæ•°
           - `user_name`: ç”¨æˆ·å
           - `post_time`: å‘å¸ƒæ—¶é—´

        2. **ä¸Šä¼ æ–‡ä»¶**: åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ CSVæ–‡ä»¶

        3. **ç”Ÿæˆè¯äº‘**: é¦–å…ˆæµ‹è¯•è¯äº‘åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ

        4. **æ¢ç´¢åˆ†æ**: æŸ¥çœ‹å„ç§å¯è§†åŒ–å›¾è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
        """)

        # æ˜¾ç¤ºåŠŸèƒ½é¢„è§ˆ
        st.header("ğŸ¯ åŠŸèƒ½é¢„è§ˆ")
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("æƒ…æ„Ÿåˆ†æ")
            st.markdown("""
            - æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
            - æƒ…æ„Ÿå¾—åˆ†ç›´æ–¹å›¾  
            - æ—¶é—´è¶‹åŠ¿åˆ†æ
            - è¯„è®ºè¯¦æƒ…æµè§ˆ
            """)

        with col2:
            st.subheader("æ–‡æœ¬åˆ†æ")
            st.markdown("""
            - åŠ¨æ€è¯äº‘ç”Ÿæˆ
            - é«˜é¢‘è¯æ±‡ç»Ÿè®¡
            - æƒ…æ„Ÿè¯æ±‡å¯¹æ¯”
            - å¤šç»´åº¦ç­›é€‰
            """)

if __name__ == "__main__":
    main()

